# -*- coding: utf-8 -*-
"""dom_matching_engine.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jn1YJ30Ttbh8uDmv6OAxOpwLSdItt3U7
"""



"""
Convert HTML to Doms.
"""
"""
DOM Extraction Utilities
Provides advanced methods to extract semantic and accessibility information from HTML
instead of sending the full DOM to the LLM.
"""

from bs4 import BeautifulSoup
from typing import List, Dict, Any, Optional
import json
import re


class DOMExtractor:
    """Extract semantic and accessibility information from HTML"""

    # Interactive element selectors (Default - Optimized for forms/controls)
    INTERACTIVE_SELECTORS = [
        'button', 'a', 'input', 'select', 'textarea',
        '[role="button"]', '[role="link"]', '[role="tab"]',
        '[role="menuitem"]', '[role="checkbox"]', '[role="radio"]',
        '[data-testid]', '[data-test]', '[data-cy]',
        '[aria-label]', '[onclick]'
    ]

    # Extended selectors for full page coverage (includes images, menus, banners)
    EXTENDED_INTERACTIVE_SELECTORS = [
        # Form elements
        'button', 'a', 'input', 'select', 'textarea', 'label',

        # Media elements
        'img', 'svg', 'video', 'audio', 'canvas',

        # List/Menu elements
        'li', 'ul', 'ol', 'nav',

        # Semantic sections
        'header', 'footer', 'main', 'aside', 'section', 'article',

        # Common clickable containers
        'div[onclick]', 'span[onclick]', 'div[class*="click"]',
        'div[class*="button"]', 'div[class*="menu"]', 'div[class*="logo"]',
        'div[class*="banner"]', 'div[class*="card"]',

        # ARIA roles
        '[role="button"]', '[role="link"]', '[role="tab"]',
        '[role="menuitem"]', '[role="checkbox"]', '[role="radio"]',
        '[role="menu"]', '[role="navigation"]', '[role="banner"]',

        # Test IDs
        '[data-testid]', '[data-test]', '[data-cy]',

        # Interactive attributes
        '[aria-label]', '[onclick]', '[aria-expanded]', '[tabindex]'
    ]

    # Attributes to extract
    IMPORTANT_ATTRIBUTES = [
        'id', 'name', 'class', 'type', 'value', 'placeholder',
        'aria-label', 'aria-labelledby', 'aria-describedby',
        'role', 'title', 'alt', 'href', 'src',
        'data-testid', 'data-test', 'data-cy', 'data-action'
    ]

    def __init__(self, html: str):
        """Initialize with HTML content"""
        self.soup = BeautifulSoup(html, 'html.parser')
        self.html = html # Store original HTML for size calculation
        self.element_counter = 0

    def extract_semantic_dom(self, full_coverage: bool = False, max_elements: int = 500) -> Dict[str, Any]:
        """
        Extract semantic DOM focusing on interactive elements with optional full page coverage.
        For large DOMs, applies priority-based filtering to stay within max_elements limit.

        Args:
            full_coverage: If True, extract all interactive elements including images, menus, banners
            max_elements: Maximum number of elements to extract (default: 500)

        Returns:
            Dictionary with extracted elements and metadata
        """
        # Determine which selectors to use based on full_coverage
        selectors_to_use = self.EXTENDED_INTERACTIVE_SELECTORS if full_coverage else self.INTERACTIVE_SELECTORS

        # 1. First, extract using CSS selectors
        elements = []
        seen_elements = set()

        for selector in selectors_to_use:
            found_elements = self.soup.select(selector)
            for element in found_elements:
                elem_id = id(element)
                if elem_id not in seen_elements and self._is_visible(element):
                    elem_data = self._extract_element_data(element)
                    if elem_data:
                        elements.append(elem_data)
                        seen_elements.add(elem_id)

        # 2. Also scan all elements for interactive heuristics (ONLY if full_coverage=True)
        if full_coverage:
            for element in self.soup.find_all(True):
                elem_id = id(element)
                if elem_id not in seen_elements and self._is_likely_interactive(element) and self._is_visible(element):
                    elem_data = self._extract_element_data(element)
                    if elem_data:
                        elements.append(elem_data)
                        seen_elements.add(elem_id)

        # 3. Priority-based filtering if we exceed max_elements
        html_size = len(self.html)
        if len(elements) > max_elements or html_size > 500000:  # 500KB threshold
            elements = self._apply_priority_filtering(elements, max_elements)

        return {
            "type": "semantic_dom",
            "total_elements": len(elements),
            "full_coverage": full_coverage,
            "elements": elements,
            "metadata": {
                "extraction_method": "comprehensive_semantic" if full_coverage else "semantic_snapshot",
                "interactive_only": not full_coverage,
                "html_size_kb": html_size / 1024,
                "filtered": len(elements) >= max_elements
            }
        }

    def _apply_priority_filtering(self, elements: List[Dict[str, Any]], max_elements: int) -> List[Dict[str, Any]]:
        """
        Apply priority-based filtering to keep only the most relevant elements.

        Priority order:
        1. Elements with data-testid or data-test (test automation targets)
        2. Elements with aria-label (accessibility labeled)
        3. Elements with meaningful text content (> 3 chars)
        4. Interactive elements (buttons, links, inputs)
        5. Elements with id attributes
        """
        def calculate_priority(elem: Dict[str, Any]) -> int:
            attrs = elem.get('attributes', {})
            text = elem.get('text', '')
            tag = elem.get('tag', '')

            priority = 0

            # Highest priority: Test IDs
            if 'data-testid' in attrs or 'data-test' in attrs or 'data-cy' in attrs:
                priority += 100

            # High priority: Aria-label (semantic accessibility)
            if 'aria-label' in attrs and attrs['aria-label']:
                priority += 80

            # Medium-high priority: Meaningful text
            if text and len(text.strip()) > 3:
                priority += 60
                # Bonus for longer, descriptive text
                if len(text.strip()) > 10:
                    priority += 20

            # Medium priority: Interactive elements
            if tag in ['button', 'a', 'input', 'select', 'textarea']:
                priority += 50

            # Low-medium priority: ID attribute
            if 'id' in attrs:
                priority += 30

            # Low priority: Class attribute
            if 'class' in attrs:
                priority += 10

            return priority

        # Sort by priority (descending) and take top max_elements
        elements_with_priority = [(elem, calculate_priority(elem)) for elem in elements]
        elements_with_priority.sort(key=lambda x: x[1], reverse=True)

        return [elem for elem, _ in elements_with_priority[:max_elements]]


    def extract_accessibility_tree(self) -> Dict[str, Any]:
        """
        Extract accessibility tree similar to what screen readers use.
        This is the most efficient method - 90% smaller than full HTML.
        """
        tree = {
            "type": "accessibility_tree",
            "nodes": []
        }

        # Start from body or html
        root = self.soup.find('body') or self.soup.find('html')
        if root:
            tree["nodes"] = self._build_accessibility_tree(root)

        return tree

    def _build_accessibility_tree(self, element, depth=0, max_depth=10) -> List[Dict[str, Any]]:
        """Recursively build accessibility tree"""
        if depth > max_depth:
            return []

        nodes = []

        # Check if element is interactive or has semantic meaning
        if self._is_accessible_element(element):
            node = {
                "role": self._get_role(element),
                "name": self._get_accessible_name(element),
                "tag": element.name,
                "attributes": self._extract_important_attributes(element),
                "text": self._get_text_content(element),
                "selector": self._generate_selector(element)
            }

            # Add children
            children = []
            for child in element.children:
                if hasattr(child, 'name'):  # Is a tag, not text
                    children.extend(self._build_accessibility_tree(child, depth + 1, max_depth))

            if children:
                node["children"] = children

            nodes.append(node)
        else:
            # Not accessible itself, but check children
            for child in element.children:
                if hasattr(child, 'name'):
                    nodes.extend(self._build_accessibility_tree(child, depth, max_depth))

        return nodes

    def extract_interactive_elements_only(self) -> List[Dict[str, Any]]:
        """
        Extract only interactive elements in a flat list.
        Fastest method for simple use cases.
        """
        elements = []

        for selector in self.INTERACTIVE_SELECTORS:
            found_elements = self.soup.select(selector)
            for element in found_elements:
                if self._is_visible(element):
                    elem_data = {
                        "tag": element.name,
                        "text": self._get_text_content(element),
                        "attributes": self._extract_important_attributes(element),
                        "selector": self._generate_selector(element),
                        "context": self._get_element_context(element)
                    }
                    elements.append(elem_data)

        return elements

    def _extract_element_data(self, element) -> Optional[Dict[str, Any]]:
        """Extract comprehensive data for a single element"""
        try:
            return {
                "tag": element.name,
                "text": self._get_text_content(element),
                "attributes": self._extract_important_attributes(element),
                "selector": self._generate_selector(element),
                "xpath": self._generate_xpath(element),
                "context": self._get_element_context(element),
                "role": self._get_role(element),
                "accessible_name": self._get_accessible_name(element)
            }
        except Exception:
            return None

    def _is_likely_interactive(self, element) -> bool:
        """Check if element is likely interactive based on multiple signals (for full coverage)"""
        # Already in interactive selectors
        if element.name in ['button', 'a', 'input', 'select', 'textarea']:
            return True

        # Has click handler
        if element.get('onclick'):
            return True

        # Has role
        if element.get('role'):
            return True

        # Has tabindex (focusable)
        if element.get('tabindex'):
            return True

        # Has ARIA attributes
        if any(element.get(attr) for attr in ['aria-label', 'aria-labelledby', 'aria-expanded']):
            return True

        # Likely clickable based on class name
        classes = ' '.join(element.get('class', [])) if element.get('class') else ''
        clickable_patterns = ['click', 'button', 'btn', 'link', 'menu', 'nav', 'logo', 'banner', 'card', 'item']
        if any(pattern in classes.lower() for pattern in clickable_patterns):
            return True

        # Images (often clickable)
        if element.name in ['img', 'svg']:
            return True

        # Common semantic elements
        if element.name in ['nav', 'header', 'footer', 'li']:
            return True

        return False

    def _is_visible(self, element) -> bool:
        """Check if element is likely visible (basic heuristic)"""
        # Check for hidden attributes
        if element.get('hidden') or element.get('aria-hidden') == 'true':
            return False

        # Check style attribute for display:none or visibility:hidden
        style = element.get('style', '')
        if 'display:none' in style.replace(' ', '') or 'visibility:hidden' in style.replace(' ', ''):
            return False

        # Check class for common hidden patterns
        classes = element.get('class', [])
        if isinstance(classes, list):
            hidden_patterns = ['hidden', 'hide', 'invisible', 'aok-hidden']
            if any(pattern in ' '.join(classes) for pattern in hidden_patterns):
                return False

        return True

    def _is_accessible_element(self, element) -> bool:
        """Check if element should be in accessibility tree"""
        # Interactive elements
        if element.name in ['button', 'a', 'input', 'select', 'textarea']:
            return True

        # Elements with roles
        if element.get('role'):
            return True

        # Elements with ARIA labels
        if element.get('aria-label') or element.get('aria-labelledby'):
            return True

        # Elements with test IDs
        if element.get('data-testid') or element.get('data-test') or element.get('data-cy'):
            return True

        # Semantic HTML5 elements
        if element.name in ['nav', 'main', 'header', 'footer', 'article', 'section']:
            return True

        return False

    def _get_role(self, element) -> str:
        """Get ARIA role or implicit role"""
        # Explicit role
        if element.get('role'):
            return element.get('role')

        # Implicit roles based on tag
        implicit_roles = {
            'button': 'button',
            'a': 'link',
            'input': 'textbox',
            'select': 'combobox',
            'textarea': 'textbox',
            'nav': 'navigation',
            'main': 'main',
            'header': 'banner',
            'footer': 'contentinfo'
        }

        return implicit_roles.get(element.name, element.name)

    def _get_accessible_name(self, element) -> str:
        """Get accessible name (what screen readers announce)"""
        # Priority order for accessible name

        # 1. aria-label
        if element.get('aria-label'):
            return element.get('aria-label')

        # 2. aria-labelledby
        if element.get('aria-labelledby'):
            label_id = element.get('aria-labelledby')
            label_elem = self.soup.find(id=label_id)
            if label_elem:
                return self._get_text_content(label_elem)

        # 3. For inputs, check associated label
        if element.name == 'input' and element.get('id'):
            label = self.soup.find('label', {'for': element.get('id')})
            if label:
                return self._get_text_content(label)

        # 4. title attribute
        if element.get('title'):
            return element.get('title')

        # 5. alt attribute (for images)
        if element.get('alt'):
            return element.get('alt')

        # 6. value attribute (for buttons/inputs)
        if element.get('value'):
            return element.get('value')

        # 7. Text content
        return self._get_text_content(element)

    def _get_text_content(self, element) -> str:
        """Get clean text content of element"""
        text = element.get_text(strip=True)
        # Limit length
        return text[:200] if text else ""

    def _extract_important_attributes(self, element) -> Dict[str, str]:
        """Extract only important attributes"""
        attrs = {}
        for attr in self.IMPORTANT_ATTRIBUTES:
            value = element.get(attr)
            if value:
                # Handle class as string
                if attr == 'class' and isinstance(value, list):
                    attrs[attr] = ' '.join(value)
                else:
                    attrs[attr] = str(value)
        return attrs

    def _generate_selector(self, element) -> str:
        """Generate a CSS selector for the element"""
        # Priority: ID > data-testid > name > class + tag

        if element.get('id'):
            return f"#{element.get('id')}"

        if element.get('data-testid'):
            return f"[data-testid='{element.get('data-testid')}']"

        if element.get('name'):
            return f"{element.name}[name='{element.get('name')}']"

        # Use tag + first class
        classes = element.get('class', [])
        if classes:
            first_class = classes[0] if isinstance(classes, list) else classes
            return f"{element.name}.{first_class}"

        return element.name

    def _generate_xpath(self, element) -> str:
        """Generate XPath for element"""
        components = []
        child = element

        for parent in element.parents:
            siblings = parent.find_all(child.name, recursive=False)
            if len(siblings) > 1:
                index = siblings.index(child) + 1
                components.append(f"{child.name}[{index}]")
            else:
                components.append(child.name)
            child = parent

            # Stop at body or after 10 levels
            if parent.name == 'body' or len(components) >= 10:
                break

        components.reverse()
        return '//' + '/'.join(components) if components else f'//{element.name}'

    def _get_element_context(self, element) -> Dict[str, Any]:
        """Get context information about element's position in DOM"""
        parent = element.parent
        siblings = list(element.next_siblings) + list(element.previous_siblings)

        # Filter to only tag siblings
        tag_siblings = [s for s in siblings if hasattr(s, 'name')][:3]

        return {
            "parent": parent.name if parent else None,
            "parent_id": parent.get('id') if parent else None,
            "parent_class": parent.get('class') if parent else None,
            "sibling_count": len(tag_siblings),
            "siblings": [s.name for s in tag_siblings]
        }


def extract_from_html(html: str, method: str = "semantic") -> Dict[str, Any]:
    """
    Convenience function to extract DOM information.

    Args:
        html: HTML content
        method: 'semantic', 'accessibility', or 'interactive'

    Returns:
        Extracted DOM data
    """
    extractor = DOMExtractor(html)

    if method == "semantic":
        return extractor.extract_semantic_dom()
    elif method == "accessibility":
        return extractor.extract_accessibility_tree()
    elif method == "interactive":
        return {"elements": extractor.extract_interactive_elements_only()}
    else:
        raise ValueError(f"Unknown method: {method}")


# Example usage
if __name__ == "__main__":
    # Test with sample HTML
    sample_html = """

<!DOCTYPE html>
<html>
<head>
	<meta charset="UTF-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0" />
	<meta http-equiv="Content-Language" content="en" />
	<title>Apache ZooKeeper</title>
	<link rel="stylesheet" href="css/bootstrap.min.css" />
	<script src="js/jquery-3.3.1.slim.min.js"></script>
	<script src="js/popper.min.js"></script>
	<script src="js/bootstrap.min.js"></script>
	<link rel="stylesheet" href="css/site.css" />
	<link rel="stylesheet" href="css/print.css" media="print" />
	<link rel="shortcut icon" href="images/favicon.ico">
</head>
<body class="topBarEnabled">
<nav class="navbar navbar-expand-lg navbar-light bg-light">
	<a class="navbar-brand" href="index.html"><img src="images/zookeeper_small.gif" height="55px"/>Apache ZooKeeper&trade;</a>
	<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
		<span class="navbar-toggler-icon"></span>
	</button>

	<div class="collapse navbar-collapse" id="navbarSupportedContent">
		<ul class="navbar-nav mr-auto">
			<li class="nav-item dropdown">
				<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
					Project
				</a>
				<div class="dropdown-menu" aria-labelledby="navbarDropdown">
					<a class="dropdown-item" href="releases.html#news">News</a>
					<a class="dropdown-item" href="releases.html">Releases</a>
					<a class="dropdown-item" href="https://cwiki.apache.org/confluence/display/ZOOKEEPER/Index">Wiki</a>
					<a class="dropdown-item" href="credits.html">Credits</a>
					<a class="dropdown-item" href="bylaws.html">Bylaws</a>
					<a class="dropdown-item" href="https://www.apache.org/licenses/">License</a>
					<a class="dropdown-item" href="privacy.html">Privacy Policy</a>
					<a class="dropdown-item" href="security.html">Security</a>
					<a class="dropdown-item" href="https://www.apache.org/foundation/thanks.html">Thanks</a>
				</div>
			</li>
			<li class="nav-item dropdown">
				<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
					Documentation
				</a>
				<div class="dropdown-menu" aria-labelledby="navbarDropdown">
                                        <a class="dropdown-item" href="doc/r3.9.4/index.html">Release 3.9.4</a>
                                        <a class="dropdown-item" href="doc/r3.8.5/index.html">Release 3.8.5</a>
                                        <a class="dropdown-item" href="doc/r3.7.2/index.html">Release 3.7.2</a>
					<a class="dropdown-item" href="documentation.html">Older Versions</a>
				</div>
			</li>
			<li class="nav-item dropdown">
				<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
					Developers
				</a>
				<div class="dropdown-menu" aria-labelledby="navbarDropdown">
					<a class="dropdown-item" href="lists.html">Mailing Lists</a>
					<a class="dropdown-item" href="irc.html">IRC Channel</a>
					<a class="dropdown-item" href="git.html">Version Control</a>
					<a class="dropdown-item" href="https://issues.apache.org/jira/browse/ZOOKEEPER">Issue Tracker</a>
					<a class="dropdown-item" href="events.html">Events</a>
				</div>
			</li>
			<li class="nav-item dropdown">
				<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
					ASF
				</a>
				<div class="dropdown-menu" aria-labelledby="navbarDropdown">
					<a class="dropdown-item" href="https://www.apache.org/foundation/" target="_blank" title="Apache Software Foundation">Apache Software Foundation</a>
					<a class="dropdown-item" href="https://www.apache.org/foundation/how-it-works.html" target="_blank" title="How Apache Works">How Apache Works</a>
					<a class="dropdown-item" href="https://www.apache.org/foundation/sponsorship.html" target="_blank" title="Sponsoring Apache">Sponsoring Apache</a>
				</div>
			</li>
		</ul>
	</div>
</nav>

<div class="container">
<!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
//-->
<h1>Welcome to Apache ZooKeeper™</h1>
<p>Apache ZooKeeper is an effort to develop and maintain an open-source server which enables highly reliable distributed coordination.</p>
<h2>What is ZooKeeper?</h2>
<p>ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. All of these kinds of services are used in some form or another by distributed applications. Each time they are implemented there is a lot of work that goes into fixing the bugs and race conditions that are inevitable. Because of the difficulty of implementing these kinds of services, applications initially usually skimp on them, which make them brittle in the presence of change and difficult to manage. Even when done correctly, different implementations of these services lead to management complexity when the applications are deployed.</p>
<p>Learn more about ZooKeeper on the <a href="https://cwiki.apache.org/confluence/display/ZOOKEEPER/Index">ZooKeeper Wiki</a>.</p>
<h2>Getting Started</h2>
<p>Start by installing ZooKeeper on a single machine or a very small cluster.</p>
<ol>
<li><a href="doc/current/index.html">Learn about</a> ZooKeeper by reading the documentation.</li>
<li><a href="releases.html">Download</a> ZooKeeper from the release page.</li>
</ol>
<h2>Getting Involved</h2>
<p>Apache ZooKeeper is an open source volunteer project under the Apache Software Foundation. We encourage you to learn about the project and contribute your expertise. Here are some starter links:</p>
<ol>
<li>See our <a href="https://cwiki.apache.org/confluence/display/ZOOKEEPER/HowToContribute">How to Contribute to ZooKeeper</a> page.</li>
<li>Give us <a href="https://issues.apache.org/jira/browse/ZOOKEEPER">feedback</a>: What can we do better?</li>
<li>Join the <a href="lists.html">mailing list</a>: Meet the community.</li>
</ol>
</div>

<footer>
    <div class="row">
        <div class="col">Copyright &copy; 2010-2020
            <a href="https://www.apache.org/">The Apache Software Foundation</a>, Licensed under the <a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License, Version 2.0</a>.<br>
            Apache ZooKeeper, ZooKeeper, Apache, the Apache feather logo, and the Apache ZooKeeper project logo are trademarks of The Apache Software Foundation.
        </div>
        <div class="col-sm-2">
            <a href="https://apache.org" id="bannerRight">
                <img src="images/asf-logo-with-feather.png" height="83px"/>
            </a>
        </div>
    </div>
</footer>
</body>
</html>

    """

    # Test semantic extraction
    extractor = DOMExtractor(sample_html)
    semantic = extractor.extract_semantic_dom()
    print("Semantic DOM:")
    print(json.dumps(semantic, indent=2))

"""
matching_engine_faiss_streamlit.py
----------------------------------
Production-ready matching engine module with:
- Semantic matching (sentence-transformers optional, TF-IDF fallback)
- Attribute-aware ranking and robust selector suggestion
- FAISS-backed vector index for scale (optional)
- Streamlit interactive demo UI

Usage (Colab):
1) Install dependencies:
   !pip install sentence-transformers faiss-cpu streamlit pandas scikit-learn

2) Run Streamlit UI:
   !streamlit run matching_engine_faiss_streamlit.py & npx localtunnel --port 8501

3) OR import MatchingEngine class normally.
"""

from typing import List, Dict, Any, Optional, Tuple
import numpy as np
import pandas as pd
import re, json, os

# ---------------- Try imports ----------------
_USE_SBERT = False
_USE_FAISS = False

try:
    from sentence_transformers import SentenceTransformer
    _USE_SBERT = True
except:
    _USE_SBERT = False

try:
    import faiss
    _USE_FAISS = True
except:
    _USE_FAISS = False

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.neighbors import NearestNeighbors


# ---------- Helper utilities ----------
def normalize_text(s: str) -> str:
    if not s:
        return ""
    return re.sub(r"\s+", " ", s).strip()

def safe_str(x: Any) -> str:
    if x is None:
        return ""
    if isinstance(x, (list, tuple)):
        return " ".join([safe_str(i) for i in x])
    if isinstance(x, dict):
        return " ".join([f"{k} {v}" for k, v in x.items() if v])
    return str(x)

def overlap_ratio(a: str, b: str) -> float:
    a_tokens = set(normalize_text(a).lower().split())
    b_tokens = set(normalize_text(b).lower().split())
    if not a_tokens or not b_tokens:
        return 0
    return len(a_tokens & b_tokens) / len(a_tokens | b_tokens)


# ---------- Flatten DOM into semantic text ----------
def flatten_element(el: Dict[str, Any]) -> str:
    parts = [f"tag: {el.get('tag','')}"]
    text = el.get("text") or el.get("accessible_name") or ""
    parts.append(f"text: {normalize_text(text)[:400]}")

    attrs = el.get("attributes", {})
    for k in ["id", "class", "aria-label", "href", "role", "type"]:
        if attrs.get(k):
            parts.append(f"{k}: {normalize_text(str(attrs[k]))}")

    parts.append(f"selector: {normalize_text(el.get('selector',''))}")
    parts.append(f"xpath: {normalize_text(el.get('xpath',''))}")

    ctx = el.get("context", {})
    parts.append(f"parent: {normalize_text(safe_str(ctx.get('parent')))}")
    parts.append(f"parent_class: {normalize_text(safe_str(ctx.get('parent_class')))}")

    return " ||| ".join(parts)


# ---------- Selector generation ----------
def escape_attr(val: str) -> str:
    return val.replace('"', '\\"')

def build_css_from_element(el: Dict[str, Any]) -> str:
    attrs = el.get("attributes", {})
    tag = el.get("tag", "a")

    # ID → strongest selector
    if attrs.get("id"):
        return f"#{attrs['id']}"

    # aria-label
    if attrs.get("aria-label"):
        return f'{tag}[aria-label="{escape_attr(attrs["aria-label"])}"]'

    # href
    if attrs.get("href"):
        href = attrs["href"]
        if len(href) > 40:
            tail = href.rstrip("/").split("/")[-1]
            return f'{tag}[href$="{escape_attr(tail)}"]'
        return f'{tag}[href="{escape_attr(href)}"]'

    # class token
    cls = attrs.get("class") or ""
    if cls:
        parts = cls.split()
        return f"{tag}.{parts[0]}"

    # role
    if el.get("role"):
        return f'{tag}[role="{escape_attr(el["role"])}"]'

    # fallback
    if el.get("xpath"):
        return f'XPATH: {el["xpath"]}'

    return tag


# ---------- Matching Engine ----------
class MatchingEngine:
    def __init__(self, elements: List[Dict[str, Any]], use_sbert=True, use_faiss=True):
        self.elements = elements
        self.use_sbert = use_sbert and _USE_SBERT
        self.use_faiss = use_faiss and _USE_FAISS

        # Build corpus
        self.corpus_texts = [flatten_element(el) for el in elements]

        # Embeddings
        if self.use_sbert:
            self.model = SentenceTransformer("all-MiniLM-L6-v2")
            self.embeddings = self.model.encode(
                self.corpus_texts, show_progress_bar=False, convert_to_numpy=True
            )
        else:
            self.vectorizer = TfidfVectorizer(ngram_range=(1, 2))
            self.embeddings = self.vectorizer.fit_transform(self.corpus_texts).toarray()

        self.dim = self.embeddings.shape[1]

        # Retrieval index
        if self.use_faiss:
            try:
                self.index = faiss.IndexFlatIP(self.dim)
                faiss.normalize_L2(self.embeddings)
                self.index.add(np.array(self.embeddings).astype("float32"))
                self.faiss_ok = True
            except:
                self.faiss_ok = False
                self.nn = NearestNeighbors(metric="cosine").fit(self.embeddings)
        else:
            self.faiss_ok = False
            self.nn = NearestNeighbors(metric="cosine").fit(self.embeddings)

    def embed_query(self, selector: str, semantic: str) -> np.ndarray:
        q = f"selector: {selector} ||| semantic: {semantic}"
        if self.use_sbert:
            vec = self.model.encode([q], convert_to_numpy=True)[0]
            if self.use_faiss:
                faiss.normalize_L2(vec.reshape(1, -1))
            return vec
        else:
            return self.vectorizer.transform([q]).toarray()[0]

    def retrieve(self, qvec, top_k):
        if self.faiss_ok:
            D, I = self.index.search(qvec.reshape(1, -1).astype("float32"), top_k)
            return I[0], D[0]
        else:
            dist, idxs = self.nn.kneighbors([qvec], n_neighbors=top_k)
            sim = 1 - dist[0]
            return idxs[0], sim

    def attribute_score(self, el, selector, semantic):
        attrs = el.get("attributes", {})
        score = 0

        # id match
        found = re.search(r"#([\w\-]+)", selector or "")
        if found and attrs.get("id") == found.group(1):
            score += 0.6

        # aria-label meaning
        if attrs.get("aria-label"):
            score += 0.3 * overlap_ratio(attrs["aria-label"], semantic)

        # href overlap
        if attrs.get("href"):
            score += 0.2 * overlap_ratio(attrs["href"], semantic)

        # class overlap
        cls_tokens = set((attrs.get("class") or "").split())
        sel_cls = set(re.findall(r"\.([\w\-]+)", selector or ""))
        if cls_tokens & sel_cls:
            score += 0.2

        return min(1, score)

    def rank(self, selector: str, semantic: str, top_k=10):
        qvec = self.embed_query(selector, semantic)
        idxs, sims = self.retrieve(qvec, top_k)

        results = []
        for i, idx in enumerate(idxs):
            el = self.elements[idx]
            base = float(sims[i])
            attr = self.attribute_score(el, selector, semantic)
            final = 0.7 * base + 0.3 * attr

            results.append(
                dict(
                    index=idx,
                    score=final,
                    base=base,
                    attr=attr,
                    element=el,
                    suggested=build_css_from_element(el),
                )
            )

        results.sort(key=lambda x: -x["score"])
        return results


# ---------- Streamlit UI ----------
def run_streamlit_app():
    import streamlit as st

    st.title("Matching Engine Demo (FAISS + TF-IDF + SBERT)")

    uploaded = st.file_uploader("Upload DOM JSON", type=["json"])
    if uploaded:
        elements = json.load(uploaded)
    else:
        st.warning("Upload a file or use sample.")
        elements = SAMPLE_ELEMENTS

    selector = st.text_input("Failed selector", "a")
    semantic = st.text_input("Semantic meaning", "Customer Service Skills")

    use_sbert = st.checkbox("Use SBERT", False)
    use_faiss = st.checkbox("Use FAISS", False)

    if st.button("Run Matching"):
        engine = MatchingEngine(elements, use_sbert, use_faiss)
        out = engine.rank(selector, semantic, top_k=10)

        df = pd.DataFrame(
            [
                dict(
                    rank=i + 1,
                    index=r["index"],
                    score=r["score"],
                    suggested=r["suggested"],
                    text=r["element"].get("text")[:120],
                )
                for i, r in enumerate(out)
            ]
        )

        st.dataframe(df)
        st.subheader("Top element full:")
        st.json(out[0]["element"])
        st.code(out[0]["suggested"], language="css")


# ---------- Sample elements for preview ----------
SAMPLE_ELEMENTS = semantic['elements']

# ---------- CLI DEMO ----------
if __name__ == "__main__":
    print("Running CLI quick test...\n")
    engine = MatchingEngine(SAMPLE_ELEMENTS)
    out = engine.rank("/html/body/div/ol[0]/li[1]/a", "click on :Learn about", top_k=5)

    #print(out)
    rows = []
    for r in out:
        el = r["element"]
        rows.append({
            "RankIndex": int(r["index"]),
            "Score": round(r["score"], 4),
            "BaseSim": round(r["base"], 4),
            "AttrScore": round(r["attr"], 4),
            "Tag": el.get("tag"),
            "Text": el.get("text"),
            "Role": el.get("role"),
            "Suggested Selector": r["suggested"],
            "XPath": el.get("xpath")
        })

    df = pd.DataFrame(rows)
    print(df)
    #print("\nRun Streamlit with:\n")
    #print("   streamlit run matching_engine_faiss_streamlit.py")